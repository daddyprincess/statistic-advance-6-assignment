{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00802de5-a358-423e-8930-1efc75e6174d",
   "metadata": {},
   "source": [
    "## Q1. Explain the assumptions required to use ANOVA and provide examples of violations that could impact the validity of the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5931579e-2b1f-42af-8e63-d46d9c1cb572",
   "metadata": {},
   "outputs": [],
   "source": [
    "Analysis of Variance (ANOVA) is a statistical method used to compare the means of three or more groups to determine if\n",
    "there are statistically significant differences among them. To use ANOVA and trust the validity of its results, certain \n",
    "assumptions must be met. Violations of these assumptions can impact the validity of ANOVA results. Here are the key\n",
    "assumptions for ANOVA:\n",
    "\n",
    "1.Independence of Observations:\n",
    "\n",
    "    ~Assumption: Observations within and between groups should be independent. This means that the data points in one\n",
    "     group should not be influenced by or related to the data points in other groups.\n",
    "    ~Violation: If observations are not independent, it can lead to pseudoreplication or inflated Type I error rates.\n",
    "     For example, if you are comparing test scores of students in different schools, and some students attend both\n",
    "    schools,it violates the independence assumption.\n",
    "    \n",
    "2.Normality:\n",
    "\n",
    "    ~Assumption: The residuals (the differences between observed values and group means) should follow a normal\n",
    "     distribution. In other words, the errors or residuals should be normally distributed within each group.\n",
    "    ~Violation: If the residuals are not normally distributed, it can lead to inaccurate p-values and confidence\n",
    "     intervals. Violations can be detected through normality tests or graphical methods like Q-Q plots.\n",
    "        \n",
    "3.Homogeneity of Variance (Homoscedasticity):\n",
    "\n",
    "    ~Assumption: The variances of the residuals should be roughly equal across all groups. In other words, the spread or\n",
    "     dispersion of data points within each group should be approximately the same.\n",
    "    ~Violation: Heteroscedasticity (unequal variances) can lead to unequal weighting of groups in the ANOVA analysis.\n",
    "     This can affect the F-statistic and p-values, making them less reliable. You can check for homogeneity of variance\n",
    "    using tests like Levene's test or by inspecting residual plots.\n",
    "    \n",
    "4.Random Sampling:\n",
    "\n",
    "    ~Assumption: Samples should be drawn randomly from the population of interest. This assumption ensures that the\n",
    "     sample is representative of the population.\n",
    "    ~Violation: Non-random sampling can introduce bias into the results and make it difficult to generalize findings to \n",
    "     the larger population.\n",
    "        \n",
    "5.Interval or Ratio Data:\n",
    "\n",
    "    ~Assumption: The dependent variable should be measured on an interval or ratio scale. ANOVA is not appropriate for\n",
    "     nominal or ordinal data.\n",
    "    ~Violation: Using ANOVA with categorical or ordinal data can lead to incorrect results.\n",
    "    \n",
    "6.Equal Group Sizes (for one-way ANOVA):\n",
    "\n",
    "    ~Assumption: In a one-way ANOVA (comparing three or more groups), it is often assumed that the group sizes are equal.\n",
    "    ~Violation: Unequal group sizes can affect the power of the ANOVA test and make it less robust. However, ANOVA is\n",
    "    still relatively robust to unequal group sizes unless the imbalance is extreme.\n",
    "    \n",
    "7.No Significant Outliers:\n",
    "\n",
    "    ~Assumption: There should be no extreme outliers in the data that could unduly influence the results.\n",
    "    ~Violation: Outliers can skew group means and affect the validity of ANOVA results. It's important to identify and\n",
    "     handle outliers appropriately.\n",
    "        \n",
    "It's important to note that ANOVA is relatively robust to violations of some assumptions, especially when sample sizes\n",
    "are large. However, when assumptions are seriously violated, alternative methods or transformations of data may be\n",
    "necessary to obtain valid results. Additionally, non-parametric tests like the Kruskal-Wallis test can be used as a \n",
    "robust alternative to ANOVA when assumptions cannot be met."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fcab865-d39c-48ac-b9bd-ab26d297c274",
   "metadata": {},
   "source": [
    "## Q2. What are the three types of ANOVA, and in what situations would each be used?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1914a3-adab-44d2-8a67-cedb840ba478",
   "metadata": {},
   "outputs": [],
   "source": [
    "Analysis of Variance (ANOVA) is a statistical technique used to analyze the variation between groups and within groups\n",
    "to determine if there are statistically significant differences among the group means. There are three main types of \n",
    "ANOVA, each designed for different situations:\n",
    "\n",
    "1.One-Way ANOVA:\n",
    "\n",
    "    ~Use: One-Way ANOVA is used when you have one independent variable (categorical) with three or more levels or groups,\n",
    "     andyou want to determine if there are statistically significant differences in the means of a continuous dependent \n",
    "    variable across these groups.\n",
    "    ~Example: You want to compare the mean test scores of students from three different schools (School A, School B, and\n",
    "     School C) to see if there are significant differences in performance.\n",
    "    \n",
    "2.Two-Way ANOVA:\n",
    "\n",
    "    ~Use: Two-Way ANOVA is used when you have two independent variables (factors), and you want to assess their\n",
    "     individual and interactive effects on a continuous dependent variable. It examines not only the main effects of\n",
    "    each factor but also their interaction effect.\n",
    "    ~Example: You want to analyze the effects of two factors, such as gender (Male/Female) and treatment (Treatment A/\n",
    "     Treatment B), on patient recovery time.\n",
    "    \n",
    "3.Repeated Measures ANOVA:\n",
    "\n",
    "    ~Use: Repeated Measures ANOVA is used when you have a single group of subjects that are measured or tested under\n",
    "     multiple conditions or time points. It is designed to assess changes within subjects over time or conditions.\n",
    "    ~Example: You want to assess whether there is a significant change in participants' blood pressure levels over three \n",
    "     different time points (baseline, 1 month, and 3 months) after they start taking a new medication.\n",
    "        \n",
    "Each type of ANOVA is suited to specific research designs and questions. Here's a brief summary of when to use each\n",
    "type:\n",
    "\n",
    "    ~One-Way ANOVA: Use when you have one independent variable (factor) with three or more levels (groups) and want to\n",
    "                    compare the means of a continuous dependent variable across these groups.\n",
    "\n",
    "    ~Two-Way ANOVA: Use when you have two independent variables (factors) and want to assess the main effects of each\n",
    "                    factor and their interaction effect on a continuous dependent variable.\n",
    "\n",
    "    ~Repeated Measures ANOVA: Use when you have a single group of subjects and want to assess changes within subjects\n",
    "                              over multiple time points or conditions.\n",
    "\n",
    "It's important to choose the appropriate type of ANOVA based on your research design and the specific hypotheses you \n",
    "want to test. Using the wrong type of ANOVA can lead to incorrect or misleading results. Additionally, it's crucial to \n",
    "ensure that the assumptions of ANOVA are met or appropriately addressed for valid and reliable results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183ff312-57b1-441a-8768-340568d0654d",
   "metadata": {},
   "source": [
    "## Q3. What is the partitioning of variance in ANOVA, and why is it important to understand this concept?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4338e73e-427a-4ca5-bbce-83fb93f98d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "The partitioning of variance in Analysis of Variance (ANOVA) is a fundamental concept that helps researchers understand\n",
    "how the total variance in a dataset is broken down into different components or sources of variation. ANOVA decomposes\n",
    "the total variance into several parts, which include:\n",
    "\n",
    "1.Total Variance (Total Sum of Squares, SST):\n",
    "\n",
    "    ~The total variance represents the overall variability in the data, capturing the differences between individual \n",
    "     data points and the grand mean of all data points. It is calculated as the sum of the squared deviations of each\n",
    "    data point from the grand mean.\n",
    "    \n",
    "            SST=∑( Xij − Xˉ )2\n",
    "\n",
    "2.Between-Group Variance (Between-Group Sum of Squares, SSB):\n",
    "\n",
    "    ~This component of variance measures the variability between different groups or categories (levels) of the\n",
    "     independent variable. It quantifies how much the group means differ from the grand mean.\n",
    "\n",
    "            SSB = ∑ ni ( Xˉi−Xˉ )2\n",
    "Where:\n",
    "\n",
    "    ~ni is the number of observations in group i.\n",
    "    ~Xˉi is the mean of group i.\n",
    "    ~Xˉ is the grand mean.\n",
    "    \n",
    "3.Within-Group Variance (Within-Group Sum of Squares, SSW):\n",
    "\n",
    "    ~This component of variance accounts for the variability within each group or category. It measures how much\n",
    "     individual data points deviate from their respective group means.\n",
    "\n",
    "            SSW=∑∑( Xij − Xˉi )2\n",
    "Where:\n",
    "\n",
    "    ~Xij is an individual data point in group i.\n",
    "    ~Xˉi is the mean of group i.\n",
    "    \n",
    "Understanding the partitioning of variance in ANOVA is crucial for several reasons:\n",
    "\n",
    "1.Hypothesis Testing: ANOVA helps test hypotheses about whether there are significant differences in means between \n",
    "  groups. By partitioning the variance into between-group and within-group components, ANOVA determines if the between-\n",
    "group variability is larger than what would be expected due to random chance.\n",
    "\n",
    "2.Interpretation: It allows researchers to interpret the relative contributions of group differences (between-group\n",
    "  variance) and random variability (within-group variance) to the total variability in the data.\n",
    "\n",
    "3.Effect Size: Researchers can calculate effect sizes, such as eta-squared (η2), which quantify the proportion of \n",
    "  variance explained by the independent variable. Effect size measures help assess the practical significance of\n",
    "observed differences.\n",
    "\n",
    "4.Model Comparison: ANOVA can be used to compare different models or treatments to see which one provides a better\n",
    "  explanation for the observed data. Understanding how much variance is explained by each model or treatment is \n",
    "essential for model selection.\n",
    "\n",
    "5.Assumptions and Model Validity: Understanding the partitioning of variance can help identify potential violations of\n",
    "  ANOVA assumptions, such as homogeneity of variances and normality of residuals. These assumptions impact the validity\n",
    "of ANOVA results.\n",
    "\n",
    "In summary, the partitioning of variance in ANOVA provides insights into the sources of variability in the data, aids in\n",
    "hypothesis testing and interpretation, and guides researchers in making informed decisions about the significance and\n",
    "practical relevance of group differences. It also helps ensure the validity and reliability of ANOVA results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3ad185-004f-4452-a165-6812fe1e05bb",
   "metadata": {},
   "source": [
    "## Q4. How would you calculate the total sum of squares (SST), explained sum of squares (SSE), and residual sum of squares (SSR) in a one-way ANOVA using Python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23ce9ee-86eb-4b49-8ac1-9920482c9921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate degrees of freedom\n",
    "df_total = len(all_data) - 1\n",
    "df_explained = len(group_means) - 1\n",
    "df_residual = df_total - df_explained\n",
    "\n",
    "# Calculate Mean Squares\n",
    "ms_explained = squared_deviations_explained / df_explained\n",
    "ms_residual = squared_deviations_residual / df_residual\n",
    "\n",
    "# Calculate the F-statistic\n",
    "F = ms_explained / ms_residual\n",
    "\n",
    "# Calculate the p-value\n",
    "p_value = 1 - stats.f.cdf(F, df_explained, df_residual)\n",
    "\n",
    "# Print F-statistic and p-value\n",
    "print(f\"F-statistic: {F:.4f}\")\n",
    "print(f\"P-value: {p_value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ce5204-6931-417c-984c-a4157bb7fd8d",
   "metadata": {},
   "source": [
    "## Q5. In a two-way ANOVA, how would you calculate the main effects and interaction effects using Python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8258d9e2-9023-49ce-a092-b6185970efac",
   "metadata": {},
   "outputs": [],
   "source": [
    "In a two-way ANOVA, you can calculate the main effects and interaction effect using Python by first performing the ANOVA\n",
    "analysis and then examining the results to extract these effects. You can use libraries like statsmodels or scipy for \n",
    "the ANOVA analysis. Here's how you can calculate the main effects and interaction effect step by step:\n",
    "\n",
    "Assuming you have a dataset with two categorical independent variables (factors) and one continuous dependent variable:\n",
    "    \n",
    "1.Import the required libraries:\n",
    "    \n",
    "    import pandas as pd\n",
    "    import statsmodels.api as sm\n",
    "    from statsmodels.formula.api import ols\n",
    "\n",
    "1.Organize your data into a DataFrame. Suppose you have a DataFrame named df with columns \"Factor1,\" \"Factor2,\" and \n",
    "  \"DependentVariable.\"\n",
    "\n",
    "2.Perform the two-way ANOVA analysis using the ols function from statsmodels:\n",
    "    \n",
    "    formula = 'DependentVariable ~ Factor1 * Factor2'\n",
    "    model = ols(formula, data=df).fit()\n",
    "    anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "    \n",
    "In the above code:\n",
    "\n",
    "    ~formula specifies the model formula with interactions between Factor1 and Factor2.\n",
    "    ~model fits the ANOVA model to your data.\n",
    "    ~anova_table contains the ANOVA results, including the main effects and interaction effect.\n",
    "    \n",
    "1.Extract the main effects and interaction effect from the anova_table:\n",
    "\n",
    "    main_effect_factor1 = anova_table.loc['Factor1', 'sum_sq'] / anova_table.loc['Factor1', 'df']\n",
    "    main_effect_factor2 = anova_table.loc['Factor2', 'sum_sq'] / anova_table.loc['Factor2', 'df']\n",
    "    interaction_effect = anova_table.loc['Factor1:Factor2', 'sum_sq'] / anova_table.loc['Factor1:Factor2', 'df']\n",
    "\n",
    "Here's what each line does:\n",
    "\n",
    "    ~anova_table.loc['Factor1', 'sum_sq'] retrieves the sum of squares for Factor1.\n",
    "    ~anova_table.loc['Factor1', 'df'] retrieves the degrees of freedom for Factor1.\n",
    "    ~Dividing the sum of squares by the degrees of freedom gives you the mean square for Factor1, which represents the\n",
    "     main effect of Factor1. Similarly, you calculate the main effect for Factor2 and the interaction effect.\n",
    "        \n",
    "Now, main_effect_factor1, main_effect_factor2, and interaction_effect will contain the main effects and interaction\n",
    "effect, respectively.\n",
    "\n",
    "These values represent the variability explained by each effect. You can also calculate F-statistics and p-values to\n",
    "assess the significance of these effects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9e5a76-ac8a-4d71-9b49-aa5cee6faef3",
   "metadata": {},
   "source": [
    "## Q6. Suppose you conducted a one-way ANOVA and obtained an F-statistic of 5.23 and a p-value of 0.02.What can you conclude about the differences between the groups, and how would you interpret these results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ed68c2-60f3-4234-bcf8-8d0ab2ad0bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "In a one-way ANOVA, the F-statistic and p-value are used to assess whether there are statistically significant\n",
    "differences among the means of three or more groups. Let's interpret the results you provided:\n",
    "\n",
    "    1.F-Statistic: The F-statistic measures the ratio of the variance between groups to the variance within groups. It\n",
    "      quantifies whether the observed differences in group means are larger than what you would expect by random chance.\n",
    "\n",
    "    2.P-Value: The p-value associated with the F-statistic tells you the probability of obtaining the observed F-\n",
    "     statistic (or an even more extreme value) if there were no real differences between the groups.\n",
    "\n",
    "In your case:\n",
    "\n",
    "    ~F-Statistic: 5.23\n",
    "    ~P-Value: 0.02\n",
    "    \n",
    "Now, let's interpret these results:\n",
    "\n",
    "    The F-statistic of 5.23 indicates that there is some variability in the data due to differences between the groups.\n",
    "    In other words, the means of the groups are not all exactly the same.\n",
    "\n",
    "    The p-value of 0.02 is the probability of observing an F-statistic as extreme as 5.23 (or more extreme) under the \n",
    "    assumption that there are no real differences between the groups. A small p-value (typically less than your chosen\n",
    "    significance level, e.g., 0.05) indicates evidence against the null hypothesis.\n",
    "\n",
    "Based on these results:\n",
    "\n",
    "    1.Null Hypothesis (H0): The null hypothesis in ANOVA is that there are no significant differences between the group\n",
    "                            means. In other words, all group means are equal.\n",
    "\n",
    "    2.Alternative Hypothesis (Ha): The alternative hypothesis is that there are significant differences between at least \n",
    "                                   two group means.\n",
    "\n",
    "Since the p-value (0.02) is less than the significance level (e.g., 0.05), you would reject the null hypothesis. This\n",
    "means you have evidence to conclude that there are statistically significant differences between at least two group \n",
    "means.\n",
    "\n",
    "In practical terms, you would need to perform post hoc tests or pairwise comparisons (e.g., Tukey's HSD test, Bonferroni\n",
    "correction) to determine which specific groups are different from each other. These tests can identify where the\n",
    "differences lie among the groups.\n",
    "\n",
    "In summary, with an F-statistic of 5.23 and a p-value of 0.02, you can conclude that there are statistically significant\n",
    "differences between at least two groups. However, further analysis is needed to determine which specific groups differ\n",
    "from each other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a35b8fb-8972-48eb-8144-322525948408",
   "metadata": {},
   "source": [
    "## Q7. In a repeated measures ANOVA, how would you handle missing data, and what are the potential consequences of using different methods to handle missing data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04066078-990e-49a7-a59a-f120973ad2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "Handling missing data in a repeated measures ANOVA is important to ensure the validity and reliability of your analysis.\n",
    "Missing data can arise for various reasons, such as participant dropouts, equipment malfunctions, or incomplete\n",
    "responses. There are several methods to handle missing data, and the choice of method can impact the results and\n",
    "conclusions of your analysis. Here are common approaches and their potential consequences:\n",
    "\n",
    "1.Listwise Deletion (Complete Case Analysis):\n",
    "\n",
    "    ~Method: Exclude cases with any missing data on any variable from the analysis.\n",
    "    ~Consequences:\n",
    "        ~Pros: Simple and easy to implement.\n",
    "        ~Cons: Reduces sample size, potentially leading to reduced statistical power and biased results if the data are\n",
    "         not missing completely at random (MCAR). It may also introduce bias if the missing data are related to the\n",
    "        variables of interest.\n",
    "        \n",
    "2.Mean Imputation:\n",
    "\n",
    "    ~Method: Replace missing values with the mean of the available values for the same variable.\n",
    "    ~Consequences:\n",
    "        ~Pros: Preserves sample size, maintains simplicity.\n",
    "        ~Cons: May underestimate variability, distort relationships between variables, and lead to biased parameter \n",
    "         estimates, especially if missingness is not MCAR. Can artificially reduce the variance and make it appear as\n",
    "        if there are no treatment effects.\n",
    "        \n",
    "3.Last Observation Carried Forward (LOCF):\n",
    "\n",
    "    ~Method: Carry forward the last observed value for each participant to replace missing data points.\n",
    "    ~Consequences:\n",
    "        ~Pros: Preserves sample size, simple.\n",
    "        ~Cons: Can introduce bias if data are not missing at random, particularly in cases of temporary changes or\n",
    "        nonlinear trends. May not accurately reflect the participant's true state.\n",
    "        \n",
    "4.Linear Interpolation:\n",
    "\n",
    "    ~Method: Interpolate missing values using linear interpolation techniques based on adjacent time points.\n",
    "    ~Consequences:\n",
    "        ~Pros: Preserves sample size, potentially more accurate than LOCF if data follow a linear trend.\n",
    "        ~Cons: Still subject to bias if the data do not follow a linear pattern or if missingness is related to the\n",
    "         variables.\n",
    "            \n",
    "5.Multiple Imputation:\n",
    "\n",
    "    ~Method: Generate multiple imputed datasets, each with different plausible values for the missing data, and analyze\n",
    "     each dataset separately. Combine results using established methods (e.g., Rubin's rules).\n",
    "    ~Consequences:\n",
    "        ~Pros: Provides unbiased parameter estimates, preserves statistical power, and accounts for the uncertainty\n",
    "         associated with missing data. Appropriate for data missing at random (MAR).\n",
    "        ~Cons: More complex and computationally intensive than other methods.\n",
    "                                                                         \n",
    "6.Maximum Likelihood Estimation (MLE):\n",
    "\n",
    "    ~Method: Use statistical software that can handle missing data using MLE. MLE estimates the model parameters while\n",
    "     accounting for missing values.\n",
    "    ~Consequences:\n",
    "        ~Pros: Provides unbiased parameter estimates, preserves statistical power, and accommodates different patterns\n",
    "         of missingness. Suitable for data missing at random (MAR).\n",
    "        ~Cons: Requires specialized software and statistical knowledge.\n",
    "                                                                         \n",
    "The choice of method should depend on the nature of the missing data, the assumptions underlying each method, and the\n",
    "goals of your analysis. It is essential to consider the potential biases and limitations associated with each approach\n",
    "and to report the method used and any assumptions made in your research findings. Additionally, sensitivity analyses \n",
    "can help assess the robustness of your results to different missing data handling methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e371f82-18b8-4bd5-bef2-f3f4d6c2134e",
   "metadata": {},
   "source": [
    "## Q8. What are some common post-hoc tests used after ANOVA, and when would you use each one? Provide an example of a situation where a post-hoc test might be necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0a3c77-9342-4b4a-aaa9-7dcd605b4e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "Post-hoc tests are used after conducting an Analysis of Variance (ANOVA) to make pairwise comparisons between groups\n",
    "when the ANOVA reveals a significant overall difference among three or more groups. These tests help identify which \n",
    "specific groups differ from each other. Several common post-hoc tests are available, and the choice of which one to use\n",
    "depends on factors such as your research design, assumptions, and objectives. Here are some common post-hoc tests and\n",
    "situations where you might use each one:\n",
    "\n",
    "1.Tukey's Honestly Significant Difference (Tukey's HSD):\n",
    "\n",
    "    ~When to Use: Tukey's HSD is a conservative post-hoc test appropriate for situations where you have equal group \n",
    "     sizes and want to control the overall Type I error rate. It is a good choice when you have multiple groups and wan\n",
    "        to compare all possible pairs.\n",
    "    ~Example: You conducted a one-way ANOVA to compare the test scores of students from five different schools. Tukey's\n",
    "     HSD can help you determine which schools have significantly different mean scores.\n",
    "        \n",
    "2.Bonferroni Correction:\n",
    "\n",
    "    ~When to Use: Bonferroni correction is a conservative method used when you want to control the familywise error rate\n",
    "     (i.e., the probability of making at least one Type I error across all comparisons). It is suitable for situations\n",
    "    with multiple comparisons, but it tends to be more conservative and may increase the risk of Type II errors.\n",
    "    ~Example: You are comparing the effects of three different treatments on a health outcome, and you want to ensure \n",
    "     that the overall error rate for any significant differences is controlled at a specific level (e.g., 0.05).\n",
    "        \n",
    "3.Dunnett's Test:\n",
    "\n",
    "    ~When to Use: Dunnett's test is appropriate when you have a control group and want to compare other groups to the\n",
    "     control group while controlling for the overall Type I error rate.\n",
    "    ~Example: In a drug trial, you have a control group receiving a placebo and several treatment groups receiving\n",
    "     different doses of a new medication. Dunnett's test can help you compare each treatment group to the control group.\n",
    "        \n",
    "4.Scheffé's Test:\n",
    "\n",
    "    ~When to Use: Scheffé's test is a conservative post-hoc test suitable for situations where you have unequal group \n",
    "     sizes and you want to control the Type I error rate when making multiple comparisons. It is robust but less\n",
    "    powerful than some other tests.\n",
    "    ~Example: You are comparing the performance of students from different grade levels (unequal group sizes), and you\n",
    "     want to control the overall Type I error rate when comparing pairs of grade levels.\n",
    "        \n",
    "5.Fisher's Least Significant Difference (LSD):\n",
    "\n",
    "    ~When to Use: Fisher's LSD is a less conservative post-hoc test appropriate for situations with equal group sizes.\n",
    "     It allows for more comparisons than Tukey's HSD but does not control the familywise error rate as rigorously.\n",
    "    ~Example: You conducted a one-way ANOVA to compare the yield of three different fertilizer treatments in a garden\n",
    "     with equal plot sizes. Fisher's LSD can help identify which pairs of treatments are significantly different.\n",
    "        \n",
    "6.Games-Howell Test:\n",
    "\n",
    "    ~When to Use: Games-Howell is suitable when group sizes are unequal, and you want to perform post-hoc tests without\n",
    "     assuming equal variances across groups. It does not require the homogeneity of variances assumption.\n",
    "    ~Example: You are comparing the performance of athletes from different sports teams, and the team sizes are uneven.\n",
    "     Games-Howell can be used to determine which teams have significantly different scores.\n",
    "        \n",
    "In summary, the choice of post-hoc test depends on the characteristics of your data, the assumptions you can make, and \n",
    "your specific research questions. It's essential to consider factors like group sizes, homogeneity of variances, and\n",
    "control of Type I error rates when selecting the most appropriate post-hoc test for your ANOVA results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0827be23-f171-4b22-bac6-27031252dd42",
   "metadata": {},
   "source": [
    "## Q9. A researcher wants to compare the mean weight loss of three diets: A, B, and C. They collect data from 50 participants who were randomly assigned to one of the diets. Conduct a one-way ANOVA using Python to determine if there are any significant differences between the mean weight loss of the three diets.Report the F-statistic and p-value, and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6add2c9-f3ad-4e57-a017-3193860a1607",
   "metadata": {},
   "outputs": [],
   "source": [
    "1.To conduct a one-way ANOVA in Python to compare the mean weight loss of three diets (A, B, and C) using the data from\n",
    "  50 participants, you can use the scipy.stats library. Here's a step-by-step guide:\n",
    "    \n",
    "1.Import the required libraries:\n",
    "    \n",
    "    import numpy as np\n",
    "    import scipy.stats as stats\n",
    "    \n",
    "1.Organize your data. Create three arrays, one for each diet:\n",
    "\n",
    "    diet_A = np.array([1.5, 2.0, 1.8, 2.3, 1.7, 2.5, 2.1, 1.9, 1.6, 2.2,\n",
    "                   1.8, 2.3, 2.0, 1.6, 1.9, 2.2, 2.1, 1.7, 1.5, 2.4,\n",
    "                   2.0, 1.8, 1.9, 2.1, 2.2, 1.7, 1.6, 2.5, 2.3, 2.4,\n",
    "                   1.6, 1.7, 2.3, 2.2, 1.9, 2.0, 1.8, 2.1, 2.4, 1.5,\n",
    "                   2.3, 1.7, 1.8, 1.6, 2.5, 2.2, 2.1, 2.0, 2.4])\n",
    "\n",
    "diet_B = np.array([1.2, 1.1, 1.3, 1.0, 1.2, 1.5, 1.4, 1.3, 1.2, 1.1,\n",
    "                   1.4, 1.3, 1.2, 1.0, 1.1, 1.5, 1.3, 1.2, 1.4, 1.0,\n",
    "                   1.1, 1.2, 1.5, 1.3, 1.4, 1.0, 1.1, 1.2, 1.3, 1.4,\n",
    "                   1.0, 1.5, 1.3, 1.2, 1.1, 1.4, 1.3, 1.0, 1.5, 1.2,\n",
    "                   1.4, 1.1, 1.3, 1.0, 1.2, 1.4, 1.5, 1.3, 1.1])\n",
    "\n",
    "diet_C = np.array([0.8, 0.9, 0.7, 0.6, 0.9, 0.7, 0.8, 0.7, 0.6, 0.9,\n",
    "                   0.7, 0.8, 0.6, 0.9, 0.7, 0.8, 0.9, 0.6, 0.7, 0.8,\n",
    "                   0.6, 0.9, 0.7, 0.8, 0.7, 0.6, 0.9, 0.7, 0.8, 0.6,\n",
    "                   0.9, 0.7, 0.8, 0.6, 0.7, 0.9, 0.8, 0.6, 0.7, 0.8,\n",
    "                   0.9, 0.6, 0.7, 0.8, 0.6, 0.9, 0.7, 0.8, 0.7, 0.6])\n",
    "\n",
    "1.Perform the one-way ANOVA:\n",
    "    \n",
    "    F_statistic, p_value = stats.f_oneway(diet_A, diet_B, diet_C)\n",
    "\n",
    "1.Interpret the results:\n",
    "\n",
    "    ~F-statistic: This statistic quantifies the ratio of the between-group variability to the within-group variability.\n",
    "     It measures whether the mean weight loss differs significantly between the three diets.\n",
    "    ~p-value: This value represents the probability of observing the obtained F-statistic or a more extreme value under\n",
    "     the null hypothesis (i.e., no differences between the diets). A small p-value (typically less than 0.05) indicates\n",
    "        evidence against the null hypothesis.\n",
    "        \n",
    "Now, you can print the F-statistic and p-value and interpret the results:\n",
    "\n",
    "    print(f\"F-statistic: {F_statistic:.2f}\")\n",
    "    print(f\"P-value: {p_value:.4f}\")\n",
    "\n",
    "    if p_value < 0.05:\n",
    "        print(\"There is significant evidence to conclude that at least one diet leads to different mean weight loss.\")\n",
    "    else:\n",
    "        print(\"There is no significant evidence to conclude that the mean weight loss differs between the diets.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fbc8212-941d-4467-93ad-d36a3e60c8b0",
   "metadata": {},
   "source": [
    "## Q10. A company wants to know if there are any significant differences in the average time it takes to complete a task using three different software programs: Program A, Program B, and Program C. They randomly assign 30 employees to one of the programs and record the time it takes each employee to complete the task. Conduct a two-way ANOVA using Python to determine if there are any main effects or interaction effects between the software programs and employee experience level (novice vs.experienced). Report the F-statistics and p-values, and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c55301a-a1d7-4619-bb65-de2d37ea4863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         sum_sq    df         F    PR(>F)\n",
      "Software              69.634658   2.0  2.113814  0.142706\n",
      "Experience            13.138395   1.0  0.797652  0.380665\n",
      "Software:Experience   37.582879   2.0  1.140857  0.336272\n",
      "Residual             395.312007  24.0       NaN       NaN\n",
      "There is no significant main effect of Software.\n",
      "There is no significant main effect of Experience.\n",
      "There is no significant interaction effect between Software and Experience.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Generate some example data (replace this with your actual data)\n",
    "np.random.seed(0)\n",
    "n = 30\n",
    "software = np.random.choice(['A', 'B', 'C'], n)\n",
    "experience = np.random.choice(['novice', 'experienced'], n)\n",
    "completion_time = np.random.normal(20, 5, n)  # Replace with actual completion times\n",
    "\n",
    "# Create a DataFrame\n",
    "data = pd.DataFrame({'Software': software, 'Experience': experience, 'CompletionTime': completion_time})\n",
    "\n",
    "# Fit a two-way ANOVA model\n",
    "formula = 'CompletionTime ~ Software + Experience + Software:Experience'\n",
    "model = ols(formula, data=data).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "# Print the ANOVA table\n",
    "print(anova_table)\n",
    "\n",
    "# Interpret the results\n",
    "alpha = 0.05  # Set your desired significance level\n",
    "\n",
    "# Check main effects\n",
    "if anova_table['PR(>F)']['Software'] < alpha:\n",
    "    print(\"There is a significant main effect of Software.\")\n",
    "else:\n",
    "    print(\"There is no significant main effect of Software.\")\n",
    "\n",
    "if anova_table['PR(>F)']['Experience'] < alpha:\n",
    "    print(\"There is a significant main effect of Experience.\")\n",
    "else:\n",
    "    print(\"There is no significant main effect of Experience.\")\n",
    "\n",
    "# Check interaction effect\n",
    "if anova_table['PR(>F)']['Software:Experience'] < alpha:\n",
    "    print(\"There is a significant interaction effect between Software and Experience.\")\n",
    "else:\n",
    "    print(\"There is no significant interaction effect between Software and Experience.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e446c7-5caa-4520-84ec-8118750e928e",
   "metadata": {},
   "source": [
    "## Q11. An educational researcher is interested in whether a new teaching method improves student test scores. They randomly assign 100 students to either the control group (traditional teaching method) or the experimental group (new teaching method) and administer a test at the end of the semester. Conduct a two-sample t-test using Python to determine if there are any significant differences in test scores between the two groups. If the results are significant, follow up with a post-hoc test to determine which group(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e96c3bb6-e4ab-4cf3-8c67-747ed4ef6336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is no significant difference between the groups (p-value >= 0.05).\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import statsmodels.stats.multicomp as multi\n",
    "\n",
    "# Generate example data (replace this with your actual data)\n",
    "np.random.seed(0)\n",
    "control_group_scores = np.random.normal(75, 10, 50)  # Replace with actual scores for the control group\n",
    "experimental_group_scores = np.random.normal(80, 10, 50)  # Replace with actual scores for the experimental group\n",
    "\n",
    "# Perform a two-sample t-test\n",
    "t_statistic, p_value = stats.ttest_ind(control_group_scores, experimental_group_scores)\n",
    "\n",
    "# Check if the results are significant\n",
    "alpha = 0.05  # Set your desired significance level\n",
    "if p_value < alpha:\n",
    "    print(\"There is a significant difference between the groups (p-value < 0.05).\")\n",
    "else:\n",
    "    print(\"There is no significant difference between the groups (p-value >= 0.05).\")\n",
    "\n",
    "# If the results are significant, perform a post-hoc test (Tukey's HSD)\n",
    "if p_value < alpha:\n",
    "    # Combine the data for post-hoc testing\n",
    "    all_scores = np.concatenate([control_group_scores, experimental_group_scores])\n",
    "    group_labels = ['Control'] * len(control_group_scores) + ['Experimental'] * len(experimental_group_scores)\n",
    "\n",
    "    # Perform Tukey's HSD test for multiple comparisons\n",
    "    tukey_result = multi.pairwise_tukeyhsd(all_scores, group_labels)\n",
    "\n",
    "    # Print the post-hoc test results\n",
    "    print(tukey_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd01b3a9-543c-45e6-8556-6a8c8ee0df8a",
   "metadata": {},
   "source": [
    "## Q12. A researcher wants to know if there are any significant differences in the average daily sales of three retail stores: Store A, Store B, and Store C. They randomly select 30 days and record the sales for each store on those days. Conduct a repeated measures ANOVA using Python to determine if there are any significant differences in sales between the three stores. If the results are significant, follow up with a post- hoc test to determine which store(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9efdce43-4b86-4e7b-903c-04ae3c288896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is a significant difference between the stores (p-value < 0.05).\n",
      " Multiple Comparison of Means - Tukey HSD, FWER=0.05  \n",
      "======================================================\n",
      "group1 group2 meandiff p-adj   lower    upper   reject\n",
      "------------------------------------------------------\n",
      "StoreA StoreB  10.4859 0.7359 -22.9593   43.931  False\n",
      "StoreA StoreC -49.4975 0.0019 -82.9426 -16.0523   True\n",
      "StoreB StoreC -59.9833 0.0001 -93.4285 -26.5382   True\n",
      "------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# Generate example data (replace this with your actual data)\n",
    "np.random.seed(0)\n",
    "store_a_sales = np.random.normal(500, 50, 30)  # Replace with actual sales data for Store A\n",
    "store_b_sales = np.random.normal(550, 60, 30)  # Replace with actual sales data for Store B\n",
    "store_c_sales = np.random.normal(480, 55, 30)  # Replace with actual sales data for Store C\n",
    "\n",
    "# Create a DataFrame\n",
    "data = pd.DataFrame({'StoreA': store_a_sales, 'StoreB': store_b_sales, 'StoreC': store_c_sales})\n",
    "\n",
    "# Perform repeated measures ANOVA\n",
    "f_statistic, p_value = stats.friedmanchisquare(data['StoreA'], data['StoreB'], data['StoreC'])\n",
    "\n",
    "# Check if the results are significant\n",
    "alpha = 0.05  # Set your desired significance level\n",
    "if p_value < alpha:\n",
    "    print(\"There is a significant difference between the stores (p-value < 0.05).\")\n",
    "else:\n",
    "    print(\"There is no significant difference between the stores (p-value >= 0.05).\")\n",
    "\n",
    "# If the results are significant, perform a post-hoc test (e.g., Tukey's HSD)\n",
    "if p_value < alpha:\n",
    "    # Stack the data for post-hoc testing\n",
    "    stacked_data = pd.melt(data.reset_index(), id_vars=['index'], value_vars=['StoreA', 'StoreB', 'StoreC'])\n",
    "    stacked_data.columns = ['Day', 'Store', 'Sales']\n",
    "\n",
    "    # Perform Tukey's HSD test for multiple comparisons\n",
    "    tukey_result = pairwise_tukeyhsd(stacked_data['Sales'], stacked_data['Store'], alpha=alpha)\n",
    "\n",
    "    # Print the post-hoc test results\n",
    "    print(tukey_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
